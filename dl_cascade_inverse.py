import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from utils import set_seed,score_ditc2softmax
import numpy as np
import torch
import torch.nn as nn
import os
import numpy as np
import torch
import torch.nn as nn
# å¯¼å…¥å¿…è¦æ¨¡å—
from dl_cascade_model import FlexibleHierNetwork
from dl_cascade_proc_dt import load_and_preprocess_all_sheets   
from dl_cascade_model import train_model
from dl_cascade_personal import compute_avg_scores, compute_max_scores, get_second_level_scores, plot_teacher_profile

def inverse_prediction(model,
                       processed_data,
                       target_score=0.8,
                       learning_rate=0.01,
                       num_iterations=1000):
    device = torch.device("cpu")
    model.to(device)
    model.eval()

    # åˆå§‹åŒ–å‚æ•°
    best_inputs = nn.ParameterDict({
        key: nn.Parameter(
            torch.empty(1, tensor.shape[1], device=device, dtype=torch.float32).normal_(0, 0.1)  # æ›´å°çš„åˆå§‹åŒ–
        )
        for key, tensor in processed_data['X_train_dict'].items()
    })
    
    # ä½¿ç”¨å¸¦è¡°å‡çš„ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(best_inputs.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.5)

    target_logit = torch.tensor([target_score], device=device, dtype=torch.float32)
    criterion = nn.MSELoss()
    loss_history = []

    for i in range(num_iterations):
        optimizer.zero_grad()
        
        logits = model(best_inputs)
        loss = criterion(logits, target_logit)
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±
        torch.nn.utils.clip_grad_norm_(best_inputs.parameters(), max_norm=1.0)
        
        optimizer.step()
        scheduler.step()  # å­¦ä¹ ç‡è¡°å‡

        loss_history.append(loss.item())

        if i % 100 == 0 and i>0:
            with torch.no_grad():
                prob = torch.sigmoid(logits).item()
                print(f"iter {i:4d} | lr={scheduler.get_last_lr()[0]:.6f} | loss={loss.item():.6f} | pred={prob:.4f}")
            
                # for param in best_inputs.parameters():
                #     noise = torch.randn_like(param) * 0.01
                #     param.add_(noise)
            # æ£€æŸ¥æ¢¯åº¦
            for name, param in best_inputs.named_parameters():
                if param.grad is not None:
                    grad_norm = param.grad.norm().item()
                    param_norm = param.norm().item()
                    print(f"  {name} æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}, å‚æ•°èŒƒæ•°: {param_norm:.6f}")
                else:
                    print(f"  {name} æ²¡æœ‰æ¢¯åº¦")

    # åç»­ä»£ç ä¿æŒä¸å˜
        optimizer.step()
        loss_history.append(loss.item())

    model.eval()
    with torch.no_grad():
        sub_scores = {}
        for key, param in best_inputs.items():
            out = model.subnets[key](param)
            sub_scores[key] = float((out).mean().item())

    best_inputs_np = {k: v.detach().cpu().numpy() for k, v in best_inputs.items()}
    return sub_scores, best_inputs_np, loss_history

def plot_inverse_path(scores_dict, avg_scores, title="Inverse Prediction Path"):
    """
    ç»˜åˆ¶é›·è¾¾å›¾å±•ç¤ºä»ç›®æ ‡è¯„åˆ†åæ¨å‡ºçš„äºŒçº§æŒ‡æ ‡å¾—åˆ†
    """
    categories = list(scores_dict.keys())
    values = list(scores_dict.values())
    avg_values = [avg_scores[cat] for cat in categories]
    
    N = len(categories)
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    values += values[:1]
    avg_values += avg_values[:1]
    angles += angles[:1]

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))

    # ç»˜åˆ¶é¢„æµ‹å¾—åˆ†
    ax.plot(angles, values, linewidth=1, linestyle='solid', label='Predicted Score')
    ax.fill(angles, values, color='blue', alpha=0.25)

    # ç»˜åˆ¶å¹³å‡å¾—åˆ†
    ax.plot(angles, avg_values, linewidth=1, linestyle='dashed', label='Average Score')

    plt.xticks(angles[:-1], categories, color='grey', size=8)
    ax.set_rlabel_position(30)
    plt.yticks([0.2, 0.4, 0.6, 0.8], ["0.2", "0.4", "0.6", "0.8"], color="grey", size=7)
    plt.ylim(0, 1)
    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
    plt.title(title)
    plt.show()

def print_recommendations(scores_dict, feature_contributions, level="second-level"):
    """
    æ‰“å°æ•™å¸ˆæå‡è·¯å¾„å»ºè®®ï¼Œä¼˜åŒ–è¾“å‡ºæ ¼å¼ï¼Œè®©äººæ›´å®¹æ˜“ç†è§£

    å‚æ•°:
        scores_dict: {äºŒçº§æŒ‡æ ‡å: å¾—åˆ†} å­—å…¸
        feature_contributions: {äºŒçº§æŒ‡æ ‡å: [(ç‰¹å¾å, é‡è¦æ€§), ...]}
        level: æç¤ºæ˜¯äºŒçº§è¿˜æ˜¯ä¸‰çº§æŒ‡æ ‡å»ºè®®
    """
    print("\nğŸ¯ Teacher Development Suggestion Report")
    print("=" * 60)

    for key in sorted(scores_dict.keys()):
        score = scores_dict[key]
        print(f"\nã€{key}ã€‘ ({level} indicator)")
        print("â†’ Current score: {:.2f}".format(score))
        print("â†’ Recommendationsï¼š")

        contributions = feature_contributions.get(key, [])
        if not contributions:
            print("  â†’ No recommendations")
            continue

        for item in contributions[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            if isinstance(item, tuple) and len(item) == 2:
                feat, contrib = item
                # å»é™¤äºŒçº§æŒ‡æ ‡å‰ç¼€ï¼Œåªä¿ç•™ä¸‰çº§æŒ‡æ ‡å
                clean_feat = feat.split('_', 1)[-1] if '_' in feat else feat
                print(f"  ğŸ”¹ {clean_feat.ljust(25)} âœ Influence the weight: {contrib:.4f}")
            else:
                print("  â†’ Invalid feature data format. Skip this item")

    print("\nğŸ’¡ Tip: The higher the value, the greater the impact. It is recommended to prioritize improving those with higher weights first")

def plot_improvement_direction(scores_dict, target_score_dict):
    """
    æ˜¾ç¤ºå½“å‰å¾—åˆ†ä¸ç›®æ ‡å¾—åˆ†ä¹‹é—´çš„å·®è·
    
    å‚æ•°:
        scores_dict: {'Basic Background': 0.8, 'Scientific Innovation': 0.75, ...}
        target_score_dict: {'Basic Background': 0.9, 'Scientific Innovation': 0.9, ...}
    """
    categories = list(scores_dict.keys())
    current_scores = list(scores_dict.values())
    target_scores = [target_score_dict.get(cat, score) for cat, score in scores_dict.items()]
    
    x = np.arange(len(categories))
    width = 0.35

    fig, ax = plt.subplots(figsize=(10, 5))
    rects1 = ax.bar(x - width/2, current_scores, width, label='Current Score', color='skyblue')
    rects2 = ax.bar(x + width/2, target_scores, width, label='Target Score', color='orange')

    ax.set_ylabel('Score')
    ax.set_title('Current performance vs Best Performance', fontsize=16)
    ax.set_xticks(x)
    ax.set_xticklabels(categories)
    ax.legend()

    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.annotate(f'{height:.2f}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom')

    autolabel(rects1)
    autolabel(rects2)
    plt.ylim(0, 1.2)
    plt.tight_layout()
    plt.show()

# ... existing code ...
def compute_feature_importance(model, X_train_dict, X_train_dict_names):
    """
    ä½¿ç”¨ç®€å•çš„æ¢¯åº¦æ–¹æ³•è®¡ç®—ç‰¹å¾é‡è¦æ€§
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        X_train_dict: è®­ç»ƒæ•°æ®å­—å…¸
        X_train_dict_names: ç‰¹å¾åç§°å­—å…¸
        
    è¿”å›:
        feature_importance: {äºŒçº§æŒ‡æ ‡å: [(ç‰¹å¾å, é‡è¦æ€§), ...]}
    """
    model.eval()
    
    # é€‰æ‹©ä¸€ä¸ªæ ·æœ¬ä½œä¸ºåŸºå‡†ï¼ˆè¿™é‡Œä½¿ç”¨æ¯ä¸ªç‰¹å¾çš„å‡å€¼ï¼‰
    baseline_data = {}
    for key, tensor in X_train_dict.items():
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼
        baseline_data[key] = torch.mean(tensor, dim=0, keepdim=True)
        baseline_data[key].requires_grad_(True)
    
    # å‰å‘ä¼ æ’­
    output = model(baseline_data)
    
    # è®¡ç®—æ¢¯åº¦
    model.zero_grad()
    output.backward()
    
    # æ”¶é›†æ¢¯åº¦ä½œä¸ºé‡è¦æ€§
    feature_importance = {}
    for key in X_train_dict_names.keys():
        if key in baseline_data and baseline_data[key].grad is not None:
            # è·å–æ¢¯åº¦çš„ç»å¯¹å€¼ä½œä¸ºé‡è¦æ€§
            importance_values = torch.abs(baseline_data[key].grad).detach().cpu().numpy()[0]
            feature_names = X_train_dict_names[key]
            
            # ç»„åˆæˆ(ç‰¹å¾å, é‡è¦æ€§)çš„åˆ—è¡¨
            feature_importance[key] = list(zip(feature_names, importance_values))
            
            # æŒ‰é‡è¦æ€§æ’åº
            feature_importance[key].sort(key=lambda x: x[1], reverse=True)
        else:
            # å¦‚æœæ²¡æœ‰æ¢¯åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
            feature_names = X_train_dict_names[key]
            feature_importance[key] = [(name, 1.0) for name in feature_names]
    
    return feature_importance

# ... existing code ...
def plot_recommendations(scores_dict, feature_contributions, top_k=5, cols=2):
    """
    Visualize teacher development recommendations in an n*m grid format
    
    Parameters:
        scores_dict: {second-level indicator: score} dictionary
        feature_contributions: {second-level indicator: [(feature name, importance), ...]}
        top_k: Number of top features to display for each indicator
        cols: Number of charts per row
    """
    # Calculate the required number of rows and columns
    n_categories = len(scores_dict)
    rows = (n_categories + cols - 1) // cols  # Round up
    
    # Create subplots
    fig, axes = plt.subplots(rows, cols, figsize=(8*cols, 4*rows))
    
    # If there's only one subplot, convert axes to a 2D array for uniform processing
    if n_categories == 1:
        axes = np.array([[axes]])
    elif rows == 1 or cols == 1:
        axes = axes.reshape(rows, cols)
    
    # Get sorted category list
    sorted_categories = sorted(scores_dict.items())
    
    # Create bar charts for each second-level indicator
    for idx, (category, score) in enumerate(sorted_categories):
        row = idx // cols
        col = idx % cols
        ax = axes[row, col]
        
        # Get feature importance for this category
        contributions = feature_contributions.get(category, [])
        
        # Take only top_k features
        top_features = contributions[:top_k] if len(contributions) >= top_k else contributions
        
        if top_features:
            # Separate feature names and importance values
            feature_names = [feat.split('_', 1)[-1] if '_' in feat else feat for feat, _ in top_features]
            importance_values = [contrib for _, contrib in top_features]
            
            # Create horizontal bar chart
            y_pos = np.arange(len(feature_names))
            bars = ax.barh(y_pos, importance_values, color='skyblue')
            
            # Set chart properties
            ax.set_yticks(y_pos)
            ax.set_yticklabels(feature_names)
            ax.set_xlabel('Feature Importance')
            ax.set_title(f'[{category}] (Current Score: {score:.2f})')
            ax.invert_yaxis()  # Most important features at the top
            
            # Add value labels on the bars
            for i, (bar, value) in enumerate(zip(bars, importance_values)):
                ax.text(bar.get_width() + max(importance_values)*0.01, bar.get_y() + bar.get_height()/2, 
                       f'{value:.3f}', ha='left', va='center', fontsize=9)
        else:
            ax.text(0.5, 0.5, 'No recommendations', horizontalalignment='center', verticalalignment='center',
                   transform=ax.transAxes, fontsize=12)
            ax.set_title(f'[{category}] (Current Score: {score:.2f})')
        
        ax.grid(axis='x', alpha=0.3)
    
    # Hide extra subplots
    for idx in range(n_categories, rows * cols):
        row = idx // cols
        col = idx % cols
        fig.delaxes(axes[row, col])
    
    plt.tight_layout()
    plt.suptitle('Teacher Development Recommendations - Feature Importance Analysis', fontsize=16, y=1.02)
    plt.show()


def plot_score_comparison(scores_dict, max_scores, avg_scores):
    """
    ç»˜åˆ¶å¾—åˆ†å¯¹æ¯”å›¾ï¼ŒåŒ…æ‹¬å½“å‰å¾—åˆ†ã€å¹³å‡å¾—åˆ†å’Œæœ€é«˜å¾—åˆ†
    
    å‚æ•°:
        scores_dict: å½“å‰é¢„æµ‹å¾—åˆ†
        max_scores: æœ€é«˜å¾—åˆ†
        avg_scores: å¹³å‡å¾—åˆ†
    """
    categories = list(scores_dict.keys())
    current_scores = [scores_dict[cat] for cat in categories]
    max_vals = [max_scores.get(cat, 0) for cat in categories]
    avg_vals = [avg_scores.get(cat, 0) for cat in categories]
    
    # è®¾ç½®æŸ±çŠ¶å›¾çš„ä½ç½®
    x = np.arange(len(categories))
    width = 0.25
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # ç»˜åˆ¶ä¸‰ç»„æŸ±çŠ¶å›¾
    rects1 = ax.bar(x - width, current_scores, width, label='current performance', color='skyblue')
    rects2 = ax.bar(x, avg_vals, width, label='average performance', color='lightcoral')
    rects3 = ax.bar(x + width, max_vals, width, label='best performance', color='lightgreen')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.annotate(f'{height:.2f}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom', fontsize=8)
    
    autolabel(rects1)
    autolabel(rects2)
    autolabel(rects3)
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Second-level indicators')
    ax.set_ylabel('Scores')
    ax.set_title('Analysis of Teacher Development Paths - Score Comparison')
    ax.set_xticks(x)
    ax.set_xticklabels(categories, rotation=45, ha='right')
    ax.legend()
    ax.set_ylim(0, 1.1)
    
    plt.tight_layout()
    plt.show()
# ... existing code ...

set_seed(5)
# å…¨å±€è®¾ç½®æ‰€æœ‰å­—ä½“å¤§å°
plt.rcParams.update({
    'font.size': 14,              # åŸºç¡€å­—ä½“å¤§å°
    'axes.titlesize': 16,         # æ ‡é¢˜å­—ä½“å¤§å°
    'axes.labelsize': 14,         # åæ ‡è½´æ ‡ç­¾å­—ä½“å¤§å°
    'xtick.labelsize': 12,        # xè½´åˆ»åº¦å­—ä½“å¤§å°
    'ytick.labelsize': 12,        # yè½´åˆ»åº¦å­—ä½“å¤§å°
    'legend.fontsize': 12,        # å›¾ä¾‹å­—ä½“å¤§å°
    'figure.titlesize': 16        # å›¾å½¢æ ‡é¢˜å­—ä½“å¤§å°
})

# 1. åŠ è½½å¹¶é¢„å¤„ç†æ‰€æœ‰sheetçš„æ•°æ®
file_path = 'teacher_info_2025_name-7-3-english.xlsx'
processed_data = load_and_preprocess_all_sheets(file_path, target_column='score')

# 2. æ„å»ºæ¨¡å‹è¾“å…¥ç»´åº¦
input_dim_dict = {
    key: tensor.shape[1] for key, tensor in processed_data['X_train_dict'].items()
}

# 3. åˆ›å»ºæ¨¡å‹
model = FlexibleHierNetwork(input_dim_dict, hidden_dims=[32, 16], output_dim=1)
if os.path.exists("best_model.pth"):
    model.load_state_dict(torch.load("best_model.pth"))
else:# 5. è®­ç»ƒæ¨¡å‹ï¼ˆç¤ºä¾‹è®­ç»ƒè¿‡ç¨‹ï¼‰
    train_model(model, processed_data['X_train_dict'], 
                processed_data['y_train'],
                processed_data['X_test_dict'], 
                processed_data['y_test'],
                epochs=500, 
                lr=1e-3)

# 6. è®¾ç½®ç›®æ ‡è¯„åˆ†ï¼ˆå½’ä¸€åŒ–åˆ°0~1åŒºé—´ï¼‰
target_score = 0.5 # è¡¨ç¤ºå¸Œæœ›è¾¾åˆ°çš„ç»¼åˆè¯„åˆ†ï¼ˆå½’ä¸€åŒ–åï¼‰

# 7. è¿è¡Œé€†æ¨è·¯å¾„åˆ†æ
scores_dict, best_inputs, loss_history = inverse_prediction(
    model, 
    processed_data, 
    target_score=target_score, 
    learning_rate = 0.1, 
    num_iterations=2000
)
scores_dict = score_ditc2softmax(scores_dict)
# ä¸­æ–‡ä¹±ç 
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
# 8. è·å–å¹³å‡å¾—åˆ†ï¼ˆç”¨äºé›·è¾¾å›¾å¯¹æ¯”ï¼‰
avg_scores = compute_avg_scores(model, processed_data['X_train_dict'])

# 9. ç»˜åˆ¶é›·è¾¾å›¾
plot_inverse_path(scores_dict, avg_scores, title=f"Path to Score {target_score}")

# 10. æ‰“å°å»ºè®®æå‡æ–¹å‘
feature_contributions = compute_feature_importance(
    model, 
    processed_data['X_train_dict'], 
    processed_data['X_train_dict_names'],
)
print_recommendations(scores_dict, feature_contributions)

# 11. å¯è§†åŒ–å»ºè®®æå‡æ–¹å‘
plot_recommendations(scores_dict, feature_contributions)

# 12. ç»˜åˆ¶å¾—åˆ†å¯¹æ¯”å›¾
max_scores = compute_max_scores(model, processed_data['X_train_dict'])
plot_score_comparison(scores_dict, max_scores, avg_scores)

plot_improvement_direction(scores_dict, max_scores)

# 11 shapè§£é‡Š
# import shap
# explainer = shap.GradientExplainer(model, background_data)
