import shap
import torch
import numpy as np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®ä¸ºéäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import pandas as pd
from typing import Dict, List, Optional
import os
import time
from utils import set_seed
set_seed(5)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
# å¤„ç†ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
def explain_with_shap(model,
                      X_dict: Dict[str, torch.Tensor],
                      feature_names_dict: Dict[str, List[str]],
                      nsamples=100):
    """
    å¯¹ FlexibleHierNetwork æ¨¡å‹è¿›è¡Œå…¨å±€ SHAP è§£é‡Šï¼ˆæŒ‰å­ç½‘ç»œï¼‰
    
    å‚æ•°:
        model: å·²è®­ç»ƒçš„æ¨¡å‹
        X_dict: æµ‹è¯•é›†è¾“å…¥ï¼ˆdictï¼Œæ¯ä¸ª key æ˜¯äºŒçº§æŒ‡æ ‡åï¼Œvalue æ˜¯ tensorï¼‰
        feature_names_dict: dictï¼Œæ¯ä¸ª key æ˜¯äºŒçº§æŒ‡æ ‡åï¼Œvalue æ˜¯ç‰¹å¾ååˆ—è¡¨
        nsamples: èƒŒæ™¯æ•°æ®é‡‡æ ·æ•°é‡
    
    è¿”å›:
        shap_values_dict: æ¯ä¸ªå­ç½‘ç»œçš„ SHAP å€¼
    """
    # è½¬ä¸º numpy
    X_np_dict = {k: v[:nsamples].cpu().numpy() for k, v in X_dict.items()}
    shap_values_dict = {}

    def subnet_forward(x, key):
        x_torch = torch.tensor(x, dtype=torch.float32)
        with torch.no_grad():
            return model.subnets[key](x_torch).cpu().numpy()

    for key in X_np_dict:
        print(f"\nğŸ” æ­£åœ¨å¯¹å­ç½‘ç»œ '{key}' è¿›è¡Œ SHAP è§£é‡Š...")

        # âœ… ä½¿ç”¨ PermutationExplainerï¼ˆPyTorch å…¼å®¹ï¼‰
        explainer = shap.PermutationExplainer(lambda x: subnet_forward(x, key), X_np_dict[key])

        try:
            shap_values = explainer(X_np_dict[key])
            shap_values_dict[key] = shap_values.values[:, :, 0]  # å–ç¬¬ä¸€ä¸ªè¾“å‡ºç»´åº¦

            # ç»˜å›¾
            print(f"SHAP summary plot for {key}:")
            plt.title(f"SHAP Summary Plot for {key}")
            shap.summary_plot(shap_values.values[..., 0], X_np_dict[key], 
                              feature_names=feature_names_dict[key],
                              max_display=10)
            # plt.tight_layout()
            plt.pause(0.1)

            plt.savefig(os.path.join('dl_cascade/data', f"shap_summary_{key}.png"),
                        dpi=300, bbox_inches='tight')
            plt.clf()  # æ¸…é™¤å½“å‰å›¾å½¢ä»¥ä¾¿ä¸‹ä¸€ä¸ªå­ç½‘ç»œçš„ç»˜å›¾
            # plt.show()
        except Exception as e:
            print(f"[ERROR] å­ç½‘ç»œ '{key}' SHAP è§£é‡Šå¤±è´¥:", e)

    return shap_values_dict


def explain_single_instance(model,
                            processed_data,
                            teacher_index=0,
                            nsamples=100,
                            show_summary=True,
                            show_waterfall=True,
                            show_force=True,
                            save_path: Optional[str] = None):
    """
    ä½¿ç”¨ SHAP å¯¹å•ä¸ªæ•™å¸ˆçš„é¢„æµ‹ç»“æœè¿›è¡Œè§£é‡Šï¼ˆä»…ä½¿ç”¨ PermutationExplainerï¼‰

    å‚æ•°:
        model: å·²è®­ç»ƒçš„æ¨¡å‹
        processed_data: åŒ…å« X_test_dict å’Œ X_test_dict_names çš„é¢„å¤„ç†æ•°æ®
        teacher_index: æ•™å¸ˆç´¢å¼•
        nsamples: é‡‡æ ·æ•°é‡ï¼ˆç”¨äº SHAP èƒŒæ™¯æ•°æ®ï¼‰
        show_summary: æ˜¯å¦æ˜¾ç¤º summary plot
        show_waterfall: æ˜¯å¦æ˜¾ç¤º waterfall plot
        show_force: æ˜¯å¦æ˜¾ç¤º force plot
        save_path: å›¾åƒä¿å­˜è·¯å¾„ï¼ˆå¦‚æœæä¾›åˆ™è‡ªåŠ¨ä¿å­˜ï¼‰

    è¿”å›:
        shap_df: åŒ…å«ç‰¹å¾åã€SHAPå€¼å’ŒåŸå§‹è¾“å…¥å€¼çš„ DataFrame
    """
    # è®¾ç½®ä¸­æ–‡æ”¯æŒ
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False

    # è·å–è¯¥æ•™å¸ˆçš„è¾“å…¥æ•°æ®ï¼ˆdict of tensorsï¼‰
    X_teacher_dict = {
        key: processed_data['X_test_dict'][key][teacher_index:teacher_index+1]
        for key in processed_data['X_test_dict']
    }

    # åˆå¹¶ä¸º flat è¾“å…¥å¼ é‡ï¼ˆç”¨äº SHAPï¼‰
    all_inputs = []
    feature_names = []

    for key in X_teacher_dict:
        input_tensor = X_teacher_dict[key].cpu().numpy().squeeze(0)
        all_inputs.extend(input_tensor.tolist())

        # è·å–å½“å‰äºŒçº§æŒ‡æ ‡ä¸‹çš„ç‰¹å¾å
        names = processed_data['X_test_dict_names'][key]
        current_features = []

        if isinstance(names, list):
            current_features = [name.split('_', 1)[-1] if '_' in name else name for name in names]
        else:
            current_feature = str(names).split('_', 1)[-1]
            current_features.append(current_feature)

        assert len(current_features) == X_teacher_dict[key].shape[1], \
            f"ç‰¹å¾åä¸ç»´åº¦ä¸åŒ¹é…ï¼š{key} ({len(current_features)} != {X_teacher_dict[key].shape[1]})"

        feature_names.extend(current_features)

    full_teacher_input = np.array(all_inputs).reshape(1, -1)
    print("åˆå¹¶åè¾“å…¥å½¢çŠ¶:", full_teacher_input.shape)
    print("ç‰¹å¾æ•°é‡:", len(feature_names))

    # æ„å»ºèƒŒæ™¯æ•°æ®
    background_list = []
    for key in processed_data['X_test_dict']:
        background_list.append(processed_data['X_test_dict'][key][:nsamples].cpu().numpy())
    background_data = np.hstack(background_list)
    print("èƒŒæ™¯æ•°æ®å½¢çŠ¶:", background_data.shape)

    # å®šä¹‰å‰å‘å‡½æ•°
    def model_forward(x):
        x_torch = torch.tensor(x, dtype=torch.float32)
        inputs = {}
        start_idx = 0
        for key in X_teacher_dict:
            dim = X_teacher_dict[key].shape[1]
            inputs[key] = x_torch[:, start_idx:start_idx + dim]
            start_idx += dim
        with torch.no_grad():
            return model(inputs).cpu().numpy()

    # âœ… åˆ›å»º PermutationExplainerï¼ˆä»…ä½¿ç”¨ PyTorchï¼‰
    # permutionExplaineræ›´é€‚åˆç”¨äºå…¨å±€ç‰¹å¾é‡è¦æ€§è¯„ä¼°ï¼Œå¿«é€Ÿäº†è§£å“ªäº›ç‰¹å¾å¯¹æ¨¡å‹çš„æ•´ä½“æ€§èƒ½å½±å“æœ€å¤§
    #  explainer æ˜¯ä¸€ä¸ªè§£é‡Šå™¨å¯¹è±¡ï¼Œå®ƒçš„ä¸»è¦åŠŸèƒ½æ˜¯è®¡ç®— SHAP å€¼ã€‚SHAP å€¼æ˜¯é€šè¿‡ç‰¹å®šçš„ç®—æ³•ï¼ˆå¦‚æ ‘æ¨¡å‹çš„ 
    # Tree SHAPã€é€šç”¨æ¨¡å‹çš„ Kernel SHAP ç­‰ï¼‰è®¡ç®—å‡ºæ¥çš„ï¼Œè¿™äº›ç®—æ³•éœ€è¦å¯¹æ¨¡å‹å’Œæ•°æ®è¿›è¡Œç‰¹å®šçš„å¤„ç†ã€‚
    explainer = shap.PermutationExplainer(model_forward, background_data)

    # è®¡ç®— SHAP å€¼
    shap_values = explainer(full_teacher_input)
    expected_value = model_forward(full_teacher_input).item() - shap_values.base_values[0]

    print(f"Expected Value (base_value): {expected_value}")

    # æ„å»º Explanation å¯¹è±¡,å¯¹è±¡æä¾›äº†ä¸€ç§æ ‡å‡†åŒ–çš„æ–¹å¼æ¥å­˜å‚¨å’Œæ“ä½œ SHAP å€¼ï¼Œä½¿å¾—è¿™äº›å€¼å¯ä»¥è¢«ä¸åŒçš„å¯è§†åŒ–å‡½æ•°
    #  æ˜¯ SHAP åº“ä¸­ç”¨äºå­˜å‚¨è§£é‡Šç»“æœçš„å¯¹è±¡,æ›´é€‚åˆç”¨äºå±€éƒ¨è§£é‡Šï¼Œè¯¦ç»†åˆ†æå•ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœï¼Œäº†è§£æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„å…·ä½“è´¡çŒ®
    explanation = shap.Explanation(
        values=shap_values.values[0],
        base_values=np.array([expected_value]),
        data=full_teacher_input[0],
        feature_names=feature_names
    )

    # æ˜¾ç¤ºå›¾è¡¨
    if show_summary:
        print("\nğŸ“Š Summary Plot:")
        # only one teacher data, so for one teacher, but 
        # summary_plot is also used for global feature importance
        # shap.summary_plot(explanation.values, explanation.data, feature_names=explanation.feature_names)
        shap.summary_plot(shap_values, full_teacher_input, feature_names=explanation.feature_names,max_display=10)
        if save_path:
            plt.savefig(f"{save_path}_summary.png")
        plt.show()

    if show_waterfall:
        print("\nğŸ“‰ Waterfall Plot:")
        # only show one teacher 
        '''
        ç”¨äºå±•ç¤ºå•ä¸ªæ ·æœ¬çš„ SHAP å€¼ï¼ˆSHapley Additive exPlanationsï¼‰åŠå…¶å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®ã€‚
        é€šè¿‡ç€‘å¸ƒå›¾ï¼Œä½ å¯ä»¥ç›´è§‚åœ°çœ‹åˆ°æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å…·ä½“å½±å“ï¼Œä»¥åŠè¿™äº›å½±å“æ˜¯å¦‚ä½•ç´¯åŠ èµ·æ¥çš„ã€‚
       1 è§£é‡Šå•ä¸ªé¢„æµ‹ï¼š
        ç€‘å¸ƒå›¾å¯ä»¥å¸®åŠ©ä½ ç†è§£æ¨¡å‹å¯¹å•ä¸ªæ ·æœ¬çš„é¢„æµ‹æ˜¯å¦‚ä½•ç”±å„ä¸ªç‰¹å¾è´¡çŒ®çš„ã€‚ä½ å¯ä»¥çœ‹åˆ°æ¯ä¸ªç‰¹å¾å¯¹æœ€ç»ˆé¢„æµ‹å€¼çš„æ­£å‘æˆ–è´Ÿå‘å½±å“ã€‚
       2 ç‰¹å¾é‡è¦æ€§ï¼š
        ç€‘å¸ƒå›¾å¯ä»¥ç›´è§‚åœ°å±•ç¤ºå“ªäº›ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“æœ€å¤§ã€‚ç‰¹å¾æŒ‰å…¶å¯¹é¢„æµ‹å€¼çš„è´¡çŒ®å¤§å°æ’åºï¼Œä½ å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°å“ªäº›ç‰¹å¾æ˜¯å…³é”®é©±åŠ¨å› ç´ ã€‚
       3 æ¨¡å‹è°ƒè¯•ï¼š
        é€šè¿‡è§‚å¯Ÿç‰¹å¾çš„è´¡çŒ®ï¼Œä½ å¯ä»¥å‘ç°æ¨¡å‹å¯èƒ½å­˜åœ¨çš„é—®é¢˜ï¼Œä¾‹å¦‚æŸäº›ç‰¹å¾çš„è´¡çŒ®æ˜¯å¦åˆç†ï¼Œæˆ–è€…æ˜¯å¦å­˜åœ¨å¼‚å¸¸å€¼å¯¹é¢„æµ‹çš„å½±å“ã€‚
        '''
        shap_values.feature_names = explanation.feature_names
        shap.plots.waterfall(shap_values[0],
                             max_display=10)
        if save_path:
            plt.savefig(f"{save_path}_waterfall.png")
        plt.show()

    if show_force:
        print("\nğŸ“ˆ Force Plot:")
        '''
        ç”¨äºå±•ç¤ºå•ä¸ªæ ·æœ¬çš„ SHAP å€¼åŠå…¶å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®ã€‚åŠ›å›¾é€šè¿‡é¢œè‰²å’Œæ¡å½¢çš„é•¿åº¦æ¥è¡¨ç¤ºæ¯ä¸ª
        ç‰¹å¾çš„æ­£å‘æˆ–è´Ÿå‘å½±å“ï¼Œéå¸¸ç›´è§‚åœ°å±•ç¤ºäº†ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„ä½œç”¨ã€‚
        1 è§£é‡Šå•ä¸ªé¢„æµ‹ï¼šåŠ›å›¾å¯ä»¥å¸®åŠ©ä½ ç†è§£æ¨¡å‹å¯¹å•ä¸ªæ ·æœ¬çš„é¢„æµ‹æ˜¯å¦‚ä½•ç”±å„ä¸ªç‰¹å¾è´¡çŒ®çš„ã€‚
        ä½ å¯ä»¥çœ‹åˆ°æ¯ä¸ªç‰¹å¾å¯¹æœ€ç»ˆé¢„æµ‹å€¼çš„æ­£å‘æˆ–è´Ÿå‘å½±å“ã€‚
        2 ç‰¹å¾å½±å“ï¼šåŠ›å›¾å¯ä»¥ç›´è§‚åœ°å±•ç¤ºå“ªäº›ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“æœ€å¤§ã€‚ç‰¹å¾æŒ‰å…¶å¯¹é¢„æµ‹å€¼çš„è´¡çŒ®å¤§å°æ’åºï¼Œ
        ä½ å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°å“ªäº›ç‰¹å¾æ˜¯å…³é”®é©±åŠ¨å› ç´ ã€‚
        3 äº¤äº’å¼å¯è§†åŒ–ï¼šåŠ›å›¾æ”¯æŒäº¤äº’å¼åŠŸèƒ½ï¼Œä½ å¯ä»¥é€šè¿‡é¼ æ ‡æ‚¬åœæˆ–ç‚¹å‡»æ¥æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼Œ
        è¿™ä½¿å¾—è§£é‡Šè¿‡ç¨‹æ›´åŠ åŠ¨æ€å’Œç›´è§‚ã€‚
        '''
        shap.force_plot(base_value = explanation.base_values[0], #æ¨¡å‹çš„åŸºç¡€å€¼ï¼Œé€šå¸¸ä¸º explainer.expected_valueï¼Œè¡¨ç¤ºæ¨¡å‹é¢„æµ‹çš„å¹³å‡å€¼æˆ–æœŸæœ›å€¼ã€‚
                        shap_values = explanation.values, #å•ä¸ªæ ·æœ¬çš„ SHAP å€¼ï¼Œæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œè¡¨ç¤ºæ¯ä¸ªç‰¹å¾å¯¹è¯¥æ ·æœ¬é¢„æµ‹çš„è´¡çŒ®ã€‚
                        features= explanation.data,#å•ä¸ªæ ·æœ¬çš„ç‰¹å¾å€¼ï¼Œæ˜¯ä¸€ä¸ªæ•°ç»„æˆ–åˆ—è¡¨ã€‚
                        feature_names=explanation.feature_names, #ç‰¹å¾åç§°åˆ—è¡¨ï¼Œç”¨äºåœ¨å›¾è¡¨ä¸­æ˜¾ç¤ºç‰¹å¾åç§°
                        link='identity',# é“¾æ¥å‡½æ•°ï¼Œç”¨äºå°† SHAP å€¼è½¬æ¢ä¸ºè¾“å‡ºå€¼ã€‚é»˜è®¤ä¸º 'identity'ï¼Œè¡¨ç¤ºç›´æ¥ä½¿ç”¨ SHAP å€¼ã€‚
                        plot_cmap='RdBu', #é¢œè‰²æ˜ å°„ï¼Œç”¨äºè¡¨ç¤ºç‰¹å¾çš„æ­£å‘å’Œè´Ÿå‘å½±å“ã€‚é»˜è®¤ä¸º 'RdBu'
                        out_names= 'force plot',# è¾“å‡ºåç§°ï¼Œç”¨äºæ˜¾ç¤ºåœ¨å›¾è¡¨çš„æ ‡é¢˜ä¸­
                        matplotlib=True)
        plt.tight_layout()
        if save_path:
            plt.savefig(f"{save_path}_force.png")
        plt.show()

    # æ„å»ºç»“æœ DataFrame
    shap_df = pd.DataFrame({
        'features': explanation.feature_names,
        'shap_values': explanation.values,
        'input_values': explanation.data
    })
    shap_df = shap_df.sort_values(by='shap_values', key=lambda x: abs(x), ascending=False)

    return shap_df

if __name__ == "__main__":
    from dl_cascade_proc_dt import load_and_preprocess_all_sheets
    from dl_cascade_model import FlexibleHierNetwork, train_model

    # åŠ è½½æ•°æ®
    file_path = r"E:\program\python\paper\teacher_analysis\dl_cascade\teacher_info_2025_name-7-3-english.xlsx"
    processed_data = load_and_preprocess_all_sheets(file_path, target_column='score')

    # æ„å»ºæ¨¡å‹
    input_dim_dict = {k: v.shape[1] for k, v in processed_data['X_train_dict'].items()}
    model = FlexibleHierNetwork(input_dim_dict, hidden_dims=[32, 16], output_dim=1)

    # è®­ç»ƒæ¨¡å‹
    train_model(
        model,
        processed_data['X_train_dict'],
        processed_data['y_train'],
        processed_data['X_test_dict'],
        processed_data['y_test'],
        epochs=500,
        lr=1e-3
    )

    # æµ‹è¯•è¾“å‡º
    model.eval()
    with torch.no_grad():
        y_pred = model(processed_data['X_test_dict'])
        print("é¢„æµ‹è¾“å‡ºç¤ºä¾‹:", y_pred[:5].squeeze().cpu().numpy())

    # æ ¹æ®è®­ç»ƒæ•°æ®ï¼Œå¯¹æ¨¡å‹è¾“å‡ºå¯¹åº”çš„ç‰¹å¾è¿›è¡Œè§£é‡Š
    explain_with_shap(model, processed_data['X_test_dict'], processed_data['X_test_dict_names'])

    # é’ˆå¯¹æŸä¸€ä¸ªæ•™å¸ˆçš„æ•°æ®ï¼Œè§£é‡Šå’Œè¯´æ˜
    # SHAP è§£é‡Š
    # teacher_index = 0
    # shap_df = explain_single_instance(
    #     model,
    #     processed_data,
    #     teacher_index=teacher_index,
    #     nsamples=100,
    #     # explainer_type="gradient",
    #     show_summary=True,
    #     show_waterfall=True,
    #     show_force=True,
    #     save_path=f"shap_teacher_{teacher_index}"
    # )

    # print("\nğŸ“Š SHAP è§£é‡Šç»“æœï¼š")
    # print(shap_df.head(20))